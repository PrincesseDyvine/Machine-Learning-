{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqXE8KlzRx8j"
      },
      "source": [
        "# Chapter 3 : Classification\n",
        "\n",
        "In Chapter 1 we mentioned that the most common supervised learning tasks are\n",
        "regression (predicting values) and classification (predicting classes). In Chapter 2 we\n",
        "explored a regression task, predicting housing values, using various algorithms such\n",
        "as Linear Regression, Decision Trees, and Random Forests (which will be explained\n",
        "in further detail in later chapters). Now we will turn our attention to classification\n",
        "systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skzDmqy3R7Nz"
      },
      "source": [
        "## The MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOutuRRHSNmp"
      },
      "source": [
        "In this chapter, we will be using the MNIST dataset, which is a set of 70,000 small\n",
        "images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. This set has been studied so much that it is often called the “Hello World” of Machine Learning: whenever\n",
        "people come up with a new classification algorithm, they are curious to see how it\n",
        "will perform on MNIST. Whenever someone learns Machine Learning, sooner or\n",
        "later they tackle MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dNlpU-cR-2R"
      },
      "source": [
        "![](https://machinelearningmastery.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvFtacejSSGp"
      },
      "source": [
        "Scikit-Learn provides many helper functions to download popular datasets. MNIST is\n",
        "one of them. The following code fetches the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Ooip1uQp79",
        "outputId": "abc4b114-a5a6-4964-a374-01225578156b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "mnist.keys()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjb4lRxfSkZx"
      },
      "source": [
        "Explore inputs and outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DsCoVNNSm5r",
        "outputId": "7521ca81-3e2b-442b-fa26-90fad8857d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ],
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOEWeWHiSuqZ"
      },
      "source": [
        "Show a sample image from the dataset : reshape the pixels to 28x28 !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "YWQw5TzIS3gJ",
        "outputId": "9ada0a2c-43bb-48f1-b1e0-2b95c10db354"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "some_digit = X[0]\n",
        "plot_digit(some_digit)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciKpO6WIS5tA"
      },
      "source": [
        "View the corresponding label of the showen image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LyZDVIdRS9pZ",
        "outputId": "5d4df961-6a35-4245-ac5c-ce50abef902f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'5'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMh5hktZTAzI"
      },
      "source": [
        "We can notice that the label was given as a string! convert it to int :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eVPvITsTAWI",
        "outputId": "90008d3f-36f0-4328-9446-9118513a1600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "y = y.astype(np.uint8)\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6-pcH1oUZ_v"
      },
      "source": [
        "Select 10,000 images for test and 60,000 images for train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUJ5XcwWUTU4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iJetq3CUkY2"
      },
      "source": [
        "## Training a Binary Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYNLtqLFUt33"
      },
      "source": [
        "Let’s simplify the problem for now and only try to identify one digit—for example,\n",
        "the number 5. This “5-detector” will be an example of a binary classifier, capable of\n",
        "distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for\n",
        "this classification task:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgAZLJaRUlen"
      },
      "outputs": [],
      "source": [
        "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits.\n",
        "y_test_5 = (y_test == 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJAWRafQU6pP"
      },
      "source": [
        "Okay, now let’s pick a classifier and train it. A good place to start is with a Stochastic\n",
        "Gradient Descent (SGD) classifier, using Scikit-Learn’s SGDClassifier class. This classifier has the advantage of being capable of handling very large datasets efficiently.\n",
        "This is in part because SGD deals with training instances independently, one at a time\n",
        "(which also makes SGD well suited for online learning), as we will see later. Let’s create\n",
        "an SGDClassifier and train it on the whole training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdQ9k6GfU9HB",
        "outputId": "588cc17d-fd4f-40e3-8722-2263d32af659"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGDClassifier(random_state=9)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_clf = SGDClassifier(random_state=9)\n",
        "sgd_clf.fit(X_train,y_train_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJIioqYkVIcW"
      },
      "source": [
        "Now you can use it to detect images of the number 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJDzahgBU_Mm",
        "outputId": "2f069252-b3f3-427c-8a88-1f93cff51589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sgd_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1qPm2l6VNCO"
      },
      "source": [
        "The classifier guesses that this image represents a 5 (True). Looks like it guessed right\n",
        "in this particular case! Now, let’s evaluate this model’s performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwEg382aVP4u"
      },
      "source": [
        "## Performance Measures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOQhtvdhVWxo"
      },
      "source": [
        "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we\n",
        "will spend a large part of this chapter on this topic. There are many performance measures available, so grab another coffee and get ready to learn many new concepts\n",
        "and acronyms!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O12HRiS6VauX"
      },
      "source": [
        "### Measuring Accuracy Using Cross-Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE1OmgOqVe3-"
      },
      "source": [
        "A good way to evaluate a model is to use cross-validation, just as we did in Chapter 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThvrF41iVwG_",
        "outputId": "e0e1223b-214b-4806-d33d-b077eac9dde3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.962  , 0.96535, 0.96495])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(sgd_clf,X_train,y_train_5,scoring=\"accuracy\",cv=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsEbv0UeWIzu"
      },
      "source": [
        "Wow! Above 90% accuracy (ratio of correct predictions) on all cross-validation folds? \n",
        "This looks amazing, doesn’t it? Well, before you get too excited, let’s look at a very\n",
        "dumb classifier that just classifies every single image in the “not-5” class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx50jUqqV8Sh",
        "outputId": "21896ccc-1987-45de-c3d1-5018c82b2f51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.91125, 0.90855, 0.90915])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class Never5Classifier(BaseEstimator):\n",
        " def fit(self, X, y=None):\n",
        "  pass\n",
        " def predict(self, X):\n",
        "  return np.zeros((len(X), 1), dtype=bool)\n",
        "\n",
        "never_5_clf = Never5Classifier()\n",
        "#Run Cross Validation with never 5 classifier\n",
        "cross_val_score(never_5_clf,X_train,y_train_5,scoring=\"accuracy\",cv=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi3XeXS9W6Kd"
      },
      "source": [
        "That’s right, it has over 90% accuracy! This is simply because only about 10% of the\n",
        "images are 5s, so if you always guess that an image is not a 5, you will be right about\n",
        "90% of the time.\n",
        "\n",
        "This demonstrates why accuracy is generally not the preferred performance measure\n",
        "for classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnXh-uiCXAjO"
      },
      "source": [
        "### Confusion Matrix\n",
        "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are\n",
        "classified as class B. For example, to know the number of times the classifier confused\n",
        "images of 5s with 3s, you would look in the 5th row and 3rd column of the confusion\n",
        "matrix\n",
        "\n",
        "To compute the confusion matrix, you first need to have a set of predictions, so they\n",
        "can be compared to the actual targets. You could make predictions on the test set, but\n",
        "let’s keep it untouched for now (remember that you want to use the test set only at the\n",
        "very end of your project, once you have a classifier that you are ready to launch).\n",
        "Instead, you can use the cross_val_predict() function.\n",
        "\n",
        "Just like the cross_val_score() function, cross_val_predict() performs K-fold\n",
        "cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLT9kQ0EWyXt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dbFuiAdXZ8t"
      },
      "source": [
        "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes\n",
        "(y_train_pred):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8qsqd9LXd0t",
        "outputId": "e4ec064f-4653-41a0-af1b-18995137cb4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[54079,   500],\n",
              "       [ 1654,  3767]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train_5,y_train_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJSkUsq5XzMU"
      },
      "source": [
        "Each row in a confusion matrix represents an actual class, while each column repre‐\n",
        "sents a predicted class. The first row of this matrix considers non-5 images (the negative class): 53,057 of them were correctly classified as non-5s (they are called true\n",
        "negatives), while the remaining 1,522 were wrongly classified as 5s (false positives).\n",
        "The second row considers the images of 5s (the positive class): 1,325 were wrongly\n",
        "classified as non-5s (false negatives), while the remaining 4,096 were correctly classified as 5s (true positives). A perfect classifier would have only true positives and true\n",
        "negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WePl-YpRX2ME",
        "outputId": "73f546d1-a018-4f98-8b10-092423377af9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[54579,     0],\n",
              "       [    0,  5421]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_perfect_predictions = y_train_5  # pretend we reached perfection\n",
        "confusion_matrix(y_train_5,y_train_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWEo9AlGX9Ru"
      },
      "source": [
        "The confusion matrix gives you a lot of information, but sometimes you may prefer a\n",
        "more concise metric. An interesting one to look at is the accuracy of the positive predictions; this is called the precision of the classifier.\n",
        "\n",
        "TP is the number of true positives, and FP is the number of false positives.\n",
        "\n",
        "A trivial way to have perfect precision is to make one single positive prediction and\n",
        "ensure it is correct (precision = 1/1 = 100%). This would not be very useful since the\n",
        "classifier would ignore all but one positive instance. So precision is typically used\n",
        "along with another metric named recall, also called sensitivity or true positive rate.\n",
        "FN is of course the number of false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YycWUcpYJmE"
      },
      "source": [
        "![](https://miro.medium.com/max/824/1*xMl_wkMt42Hy8i84zs2WGg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPz7xIksY7Lr"
      },
      "source": [
        "Calculate Precision and recall from confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL7UBtzvDA09",
        "outputId": "530b3510-15e2-4fd0-863e-2f0f0fb1e0d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[54079,   500],\n",
              "       [ 1654,  3767]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_train_5, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2drq7WaY_nT",
        "outputId": "8a202144-fdfa-4c82-c26f-4e4c5d4b35c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prec 0.8828216545582377 recall 0.6948902416528315\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(y_train_5, y_train_pred)\n",
        "precision = cm[1,1] / (cm[1,1] + cm[0,1])\n",
        "recall = cm[1,1] / (cm[1,1] + cm[1,0])\n",
        "\n",
        "print(\"prec\",precision,\"recall\",recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMOnXzmtYnF1"
      },
      "source": [
        "Scikit-Learn provides several functions to compute classifier metrics, including precision and recall:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmkY_qn4X49s",
        "outputId": "e463e5cf-35ae-4217-f362-9046924f1ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision: 0.8828216545582377\n",
            "recall: 0.6948902416528315\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"precision:\",precision_score(y_train_5, y_train_pred))\n",
        "print(\"recall:\",recall_score(y_train_5, y_train_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqrl_2IHZp8r"
      },
      "source": [
        "Now your 5-detector does not look as shiny as it did when you looked at its accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrUt7RciZeyi"
      },
      "source": [
        "It is often convenient to combine precision and recall into a single metric called the F1\n",
        "score, in particular if you need a simple way to compare two classifiers. The F1\n",
        " score is \n",
        "the harmonic mean of precision and recall. Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values.\n",
        "As a result, the classifier will only get a high F1\n",
        " score if both recall and precision are\n",
        "high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xyM9pW7Zx_z"
      },
      "source": [
        "<img src=\"https://datascience103579984.files.wordpress.com/2019/04/capture3-24.png\" height = 150/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMKUGr3sZ-2j",
        "outputId": "55c0c92e-4904-4cd4-b016-a15427565be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score 0.77766308835673\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"f1_score\",f1_score(y_train_5, y_train_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxoWgEG1anvS"
      },
      "source": [
        "The F1\n",
        "score favors classifiers that have similar precision and recall. This is not always\n",
        "what you want: in some contexts you mostly care about precision, and in other contexts you really care about recall. For example, if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many\n",
        "good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your\n",
        "product (in such cases, you may even want to add a human pipeline to check the classifier’s video selection). On the other hand, suppose you train a classifier to detect\n",
        "shoplifters on surveillance images: it is probably fine if your classifier has only 30%\n",
        "precision as long as it has 99% recall (sure, the security guards will get a few false\n",
        "alerts, but almost all shoplifters will get caught).\n",
        "Unfortunately, you can’t have it both ways: increasing precision reduces recall, and\n",
        "vice versa. This is called the precision/recall tradeoff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwlqKd0fW9Gn"
      },
      "source": [
        "## Multiclass Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubs33ZEaZnE1"
      },
      "source": [
        "Whereas binary classifiers distinguish between two classes, multiclass classifiers (also\n",
        "called multinomial classifiers) can distinguish between more than two classes.\n",
        "\n",
        "one way to create a system that can classify the digit images into 10\n",
        "classes (from 0 to 9) is to train 10 binary classifiers, one for each digit (a 0-detector, a\n",
        "1-detector, a 2-detector, and so on). Then when you want to classify an image, you get\n",
        "the decision score from each classifier for that image and you select the class whose\n",
        "classifier outputs the highest score. This is called the one-versus-all (OvA) strategy \n",
        "(also called one-versus-the-rest)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aab21G_yjdnW"
      },
      "source": [
        "Another strategy is to train a binary classifier for every pair of digits: one to distinguish 0s and 1s, another to distinguish 0s and 2s, another for 1s and 2s, and so on.\n",
        "This is called the one-versus-one (OvO) strategy. If there are N classes, you need to\n",
        "train N × (N – 1) / 2 classifiers. For the MNIST problem, this means training 45\n",
        "binary classifiers! When you want to classify an image, you have to run the image\n",
        "through all 45 classifiers and see which class wins the most duels. The main advantage of OvO is that each classifier only needs to be trained on the part of the training\n",
        "set for the two classes that it must distinguish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFuL9hbgjkQq"
      },
      "source": [
        "Scikit-Learn detects when you try to use a binary classification algorithm for a multiclass classification task, and it automatically runs OvA (except for SVM classifiers for\n",
        "which it uses OvO). Let’s try this with the SGDClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrX_-7aYI73j",
        "outputId": "4ee34ba7-b36a-48db-b5f4-b2c29fa0287d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK5nobtQZmC5",
        "outputId": "a4038659-642d-472b-e34e-d6ed0ea7bf8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5], dtype=uint8)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "some_digit = X[0]\n",
        "sgd_clf.fit(X_train, y_train) \n",
        "sgd_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytQgRkQtoAmG"
      },
      "source": [
        "That was easy! This code trains the SGDClassifier on the training set using the original target classes from 0 to 9 (y_train), instead of the 5-versus-all target classes\n",
        "(y_train_5). Then it makes a prediction (a correct one in this case). Under the hood,\n",
        "Scikit-Learn actually trained 10 binary classifiers, got their decision scores for the\n",
        "image, and selected the class with the highest score.\n",
        "To see that this is indeed the case, you can call the decision_function() method.\n",
        "Instead of returning just one score per instance, it now returns 10 scores, one per class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ej2JvMWoEzP",
        "outputId": "b0698c4f-4f51-45cb-80be-9a0f4badfa58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-13805.29931575, -31807.06273982,  -8700.11308457,\n",
              "           745.12896185, -17328.08897781,   4822.3943465 ,\n",
              "        -15831.42048265, -13723.09626341, -10814.92898366,\n",
              "         -5156.74807764]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get decisions from classifier for some digit\n",
        "some_digit_scores =  sgd_clf.decision_function([some_digit])\n",
        "some_digit_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd6sS5xdqp6J"
      },
      "source": [
        "Get classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5IvALPVpQR0",
        "outputId": "3e786b5f-6f78-4d4c-f72f-629204bd1be7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sgd_clf.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKgwpWUIqu2c"
      },
      "source": [
        "get output index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtq3qqOppYNt",
        "outputId": "a959c664-dfb2-4e25-fe10-33bccdecdcf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(some_digit_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC_s5tahqbL7"
      },
      "source": [
        "If you want to force ScikitLearn to use one-versus-one or one-versus-all, you can use\n",
        "the OneVsOneClassifier or OneVsRestClassifier classes. Simply create an instance\n",
        "and pass a binary classifier to its constructor. For example, this code creates a multiclass classifier using the OvO strategy, based on a SGDClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjQpsRMQqSNq"
      },
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
        "ovo_clf.fit(X_train, y_train)\n",
        "ovo_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGexitqpqgnU"
      },
      "outputs": [],
      "source": [
        "len(ovo_clf.estimators_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc1OLZxyMaUj"
      },
      "outputs": [],
      "source": [
        "ovo_clf.decision_function([X[178]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GrvJa8DM2v5"
      },
      "outputs": [],
      "source": [
        "np.argmax(ovo_clf.decision_function([X[178]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PfyUFn9M-Tw"
      },
      "outputs": [],
      "source": [
        "plot_digit(X[178])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EXjt-Q5NDLm"
      },
      "outputs": [],
      "source": [
        "y[178]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5C6ZH5ErU4v"
      },
      "source": [
        "Now of course you want to evaluate these classifiers. As usual, you want to use cross\u0002validation. Let’s evaluate the SGDClassifier’s accuracy using the cross_val_score()\n",
        "function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75W6iNhTrcfw"
      },
      "outputs": [],
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1lsyARXrzK2"
      },
      "source": [
        "It gets over 84% on all test folds. If you used a random classifier, you would get 10%\n",
        "accuracy, so this is not such a bad score, but you can still do much better. For example, simply scaling the inputs (as discussed in Chapter 2) increases accuracy above\n",
        "89%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0qpG-jGPr2Ib",
        "outputId": "0e48a1bb-f901-48ae-d14a-8944fb240f9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.90225, 0.896  , 0.89935])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = #Normalize the images\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
        "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAq_rr2bsgYD"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jroeFoH3sqyS"
      },
      "source": [
        "Of course, if this were a real project, you would follow the steps in your Machine\n",
        "Learning project checklist: exploring data preparation options, trying out\n",
        "multiple models, shortlisting the best ones and fine-tuning their hyperparameters\n",
        "using GridSearchCV, and automating as much as possible, as you did in the previous\n",
        "chapter. Here, we will assume that you have found a promising model and you want\n",
        "to find ways to improve it. One way to do this is to analyze the types of errors it\n",
        "makes.\n",
        "First, you can look at the confusion matrix. You need to make predictions using the\n",
        "cross_val_predict() function, then call the confusion_matrix() function, just like\n",
        "you did earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_knm0misjKW"
      },
      "outputs": [],
      "source": [
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "conf_mx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C3EHi_6vB2Y"
      },
      "source": [
        "That’s a lot of numbers. It’s often more convenient to look at an image representation\n",
        "of the confusion matrix, using Matplotlib’s matshow() function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV9UkoXMu-oD"
      },
      "outputs": [],
      "source": [
        "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFxYZ1GjvtOZ"
      },
      "source": [
        "This confusion matrix looks fairly good, since most images are on the main diagonal,\n",
        "which means that they were classified correctly. The 5s look slightly darker than the\n",
        "other digits, which could mean that there are fewer images of 5s in the dataset or that\n",
        "the classifier does not perform as well on 5s as on other digits. In fact, you can verify\n",
        "that both are the case.\n",
        "Let’s focus the plot on the errors. First, you need to divide each value in the confusion\n",
        "matrix by the number of images in the corresponding class, so you can compare error rates instead of absolute number of errors (which would make abundant classes look\n",
        "unfairly bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2wxeJatwT0D"
      },
      "outputs": [],
      "source": [
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqlQ73oXwVfd"
      },
      "source": [
        "Now let’s fill the diagonal with zeros to keep only the errors, and let’s plot the result:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK_Z5X6FwVDq"
      },
      "outputs": [],
      "source": [
        "np.fill_diagonal(norm_conf_mx, 0)\n",
        "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2khIfi7RfppG"
      },
      "source": [
        "Now you can clearly see the kinds of errors the classifier makes. Remember that rows\n",
        "represent actual classes, while columns represent predicted classes. The column for\n",
        "class 8 is quite bright, which tells you that many images get misclassified as 8s. However, the row for class 8 is not that bad, telling you that actual 8s in general get properly classified as 8s. As you can see, the confusion matrix is not necessarily\n",
        "symmetrical. You can also see that 3s and 5s often get confused (in both directions).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTd9JlegfxV8"
      },
      "source": [
        "Analyzing individual errors can also be a good way to gain insights on what your\n",
        "classifier is doing and why it is failing, but it is more difficult and time-consuming.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ior74ZCCf0aV"
      },
      "outputs": [],
      "source": [
        "cl_a, cl_b = 3, 5\n",
        "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
        "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
        "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
        "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzIXDdUsgjcQ"
      },
      "source": [
        "## Multilabel Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWj7fehIg9rv"
      },
      "source": [
        "Until now each instance has always been assigned to just one class. In some cases you\n",
        "may want your classifier to output multiple classes for each instance. For example,\n",
        "consider a face-recognition classifier: what should it do if it recognizes several people\n",
        "on the same picture? Of course it should attach one tag per person it recognizes. Say\n",
        "the classifier has been trained to recognize three faces, Alice, Bob, and Charlie; then\n",
        "when it is shown a picture of Alice and Charlie, it should output [1, 0, 1] (meaning\n",
        "“Alice yes, Bob no, Charlie yes”). Such a classification system that outputs multiple\n",
        "binary tags is called a multilabel classification system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC5ynY3Igotb"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "y_train_large = (y_train >= 7)\n",
        "y_train_odd = (y_train % 2 == 1)\n",
        "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "knn_clf = # Use KNN Classifier\n",
        "knn_clf.fit(X_train, y_multilabel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwsVxK4XhTFw"
      },
      "source": [
        "This code creates a y_multilabel array containing two target labels for each digit\n",
        "image: the first indicates whether or not the digit is large (7, 8, or 9) and the second\n",
        "indicates whether or not it is odd. The next lines create a KNeighborsClassifier\n",
        "instance (which supports multilabel classification, but not all classifiers do) and we\n",
        "train it using the multiple targets array. Now you can make a prediction, and notice\n",
        "that it outputs two labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8wS98XDhT3q"
      },
      "outputs": [],
      "source": [
        "knn_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGQ6Dbd1hkPB"
      },
      "source": [
        "And it gets it right! The digit 5 is indeed not large (False) and odd (True).\n",
        "There are many ways to evaluate a multilabel classifier, and selecting the right metric\n",
        "really depends on your project. For example, one approach is to measure the F1\n",
        " score\n",
        "for each individual label (or any other binary classifier metric discussed earlier), then\n",
        "simply compute the average score. This code computes the average F1\n",
        "score across all\n",
        "labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZXoXnueiRQt"
      },
      "outputs": [],
      "source": [
        "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
        "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZzIXDdUsgjcQ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}