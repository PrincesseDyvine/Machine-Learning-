# -*- coding: utf-8 -*-
"""Copie de Chapter 3.2 : Exercice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jBPSBPQu4XUne17xQzmMFcP9QgzHNOYs

# Chapter 3.2 : Exercice

## Titanic Dataset

The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.
"""

import os
import urllib.request

TITANIC_PATH = os.path.join("datasets", "titanic")
DOWNLOAD_URL = "https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/"

def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):
    if not os.path.isdir(path):
        os.makedirs(path)
    for filename in ("train.csv", "test.csv"):
        filepath = os.path.join(path, filename)
        if not os.path.isfile(filepath):
            print("Downloading", filename)
            urllib.request.urlretrieve(url + filename, filepath)

fetch_titanic_data()

import pandas as pd

def load_titanic_data(filename, titanic_path=TITANIC_PATH):
    csv_path = os.path.join(titanic_path, filename)
    return pd.read_csv(csv_path)

train_data = load_titanic_data("train.csv")
test_data = load_titanic_data("test.csv")

train_data = train_data.set_index("PassengerId")
test_data = test_data.set_index("PassengerId")

"""The data is already split into a training set and a test set. However, the test data does not contain the labels: your goal is to train the best model you can using the training data, then make your predictions on the test data and upload them to Kaggle to see your final score."""

train_data.info()

"""The attributes have the following meaning:

PassengerId: a unique identifier for each passenger
Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.
Pclass: passenger class.
Name, Sex, Age: self-explanatory
SibSp: how many siblings & spouses of the passenger aboard the Titanic.
Parch: how many children & parents of the passenger aboard the Titanic.
Ticket: ticket id
Fare: price paid (in pounds)
Cabin: passenger's cabin number
Embarked: where the passenger embarked the Titanic
"""

train_data.head()

"""## data Preprocessing

### For Numerical data
- Use simple imputer to replace null/nan values 
- Normalize the data

### For categorical data
- use simple imputer (most frequent) 
- use one hot encoding
"""

# Numerical pipeline
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

num_pipeline = Pipeline([ 
 ('imputer', SimpleImputer(strategy="median")),
 ('std_scaler', StandardScaler() )])

# categorical pipeline
from sklearn.preprocessing import OneHotEncoder
cat_pipeline = Pipeline([
  ('imputer', SimpleImputer(strategy="most frequent")),
  ('OneHot', OneHotEncoder() )])

"""### Join the numerical and categorical pipelines:"""

from sklearn.compose import ColumnTransformer

num_attribs = ["Age", "SibSp", "Parch", "Fare"]
cat_attribs = ["Pclass", "Sex", "Embarked"]

Full_pipeline= ColumnTransformer([
 ("num", num_pipeline, num_attribs),
 ("cat", cat_pipeline, cat_attribs),                                 
])

# preprocess pipeline

#Apply pipeline
X_train =

y_train=

# Apply estimators (with crossvalidation)